{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep sketches for recognition experiment\n",
    "\n",
    "Goal: To get empirical estimates of collab and solo sketch recognizability to compare with VGG-based recognizability estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define file paths, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rendering_helpers' from 'rendering_helpers.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "svg_dir = os.path.abspath(os.path.join(sketch_dir,'svg'))\n",
    "png_dir = os.path.abspath(os.path.join(sketch_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'python'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "import rendering_helpers as srh\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)\n",
    "reload(srh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load in group data csv\n",
    "\n",
    "note: game '9053-d3a0c1d9-cb81-4bdd-a572-5e38b91b33e9' in pilot1 missing stroke data from the first sheep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique gameIDs = 90\n"
     ]
    }
   ],
   "source": [
    "# which iteration name should we use?\n",
    "iterationName = 'pilot2'\n",
    "\n",
    "## load in sketch-level dataframe \n",
    "M = pd.read_csv(os.path.join(csv_dir,'collabdraw_sketch_{}.csv'.format(iterationName)))\n",
    "print 'Number of unique gameIDs = {}'.format(M.gameID.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### render sketches using svg data (can be skipped if already rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runThis = 0\n",
    "reload(srh)\n",
    "if runThis:\n",
    "    ## render out all svg\n",
    "    for name, group in D.groupby(['gameID','trialNum']):   \n",
    "\n",
    "        ## get list of svg\n",
    "        this_svg, bounds = srh.make_svg_list(group,crop=True)\n",
    "\n",
    "        ## construct filename\n",
    "        g = np.unique(group['gameID'])[0]\n",
    "        l = np.unique(group['className'])[0]\n",
    "        r = np.unique(group['repetition'])[0]    \n",
    "        t = np.unique(group['trialNum'])[0]\n",
    "        c = np.unique(group['condition'])[0]\n",
    "        s = 'both'\n",
    "        e = 'pilot2'\n",
    "        this_fname = '{}_{}_{}_{}_{}_{}_{}'.format(g,l,r,t,c,s,e)\n",
    "\n",
    "        print 'Rendering out svg data from game: {}  trial: {}'.format(g,t)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        ## render to svg file\n",
    "        padding = 10\n",
    "        stroke_pct_canvas = 0.02 ## what fraction of image size should a stroke's width be?\n",
    "        stroke_width = np.int(np.round(stroke_pct_canvas*bounds))\n",
    "\n",
    "        srh.render_svg(this_svg,\n",
    "                     out_dir=svg_dir,\n",
    "                     viewbox=[0, 0, bounds+padding, bounds+padding],\n",
    "                     stroke_width = stroke_width,\n",
    "                     stroke_color = 'black',\n",
    "                     out_fname= '{}.svg'.format(this_fname)) \n",
    "\n",
    "    ## get svg path list for rendered out svg\n",
    "    svg_paths = srh.generate_svg_path_list(os.path.join(sketch_dir,'svg'))    \n",
    "\n",
    "    ## convert all svg to png\n",
    "    srh.svg_to_png(svg_paths,base_dir=sketch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload pngs to s3 (can be skipped if already uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import boto\n",
    "bucket_name = 'collabdraw-collab8-sketches'\n",
    "path_to_png = os.path.join(sketch_dir,'png')\n",
    "runThis = 0\n",
    "if runThis:\n",
    "    conn = boto.connect_s3()\n",
    "    b = conn.create_bucket(bucket_name) ### if bucket already exists, then get_bucket, else create_bucket\n",
    "    for ind,im in enumerate(os.listdir(path_to_png)):\n",
    "        if im[-3:]=='png':\n",
    "            print ind, im\n",
    "            k = b.new_key(im)\n",
    "            k.set_contents_from_filename(os.path.join(path_to_png,im))\n",
    "            k.set_acl('public-read')\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build stimulus dictionary\n",
    "\n",
    "png filenames are built: gameID + ClassName + repetition + trialNum + condition + sketcherId + iterationName.\n",
    "\n",
    "e.g., '0019-78badd4a-e1f8-467e-80fa-bfbcec36e346_bear_0_7_solo_both_pilot2.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get list of all images available\n",
    "path_to_png = os.path.join(sketch_dir,'png')\n",
    "png_list = [i for i in os.listdir(path_to_png) if i[-3:]=='png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## manually subset columns of metadata dataframe that you want to have available as part of recog experiment stimdict\n",
    "stimdict_cols = ['assignmentId','hitId','className','condition',\\\n",
    "                 'expDesign','firstMover','gameID','humanStrokes',\\\n",
    "                 'iterationName','numStrokes','repetition','robotStrokes',\\\n",
    "                 'sketcherId','sketchDuration','time','trialNum']\n",
    "\n",
    "M2 = M[stimdict_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally 2876 images in metadata. 2848 render-able images on S3.\n"
     ]
    }
   ],
   "source": [
    "def build_url(row,url_stem = 'https://s3.amazonaws.com',\n",
    "              bucket_name = 'BUCKET-NAME',\n",
    "              gameID = 'GAME-ID-PLACEHOLDER',\n",
    "              className = 'CLASSNAME',\n",
    "              repetition = 'REPETITION',\n",
    "              trialNum = 'TRIAL-NUM',\n",
    "              condition = 'CONDITION',\n",
    "              sketcherId = 'SKETCHERID',\n",
    "              iterationName = 'ITERATION-NAME'):\n",
    "\n",
    "    return '{}/{}/{}_{}_{}_{}_{}_{}_{}.png'.format(url_stem,bucket_name,\\\n",
    "                                              gameID,className,repetition,\\\n",
    "                                              trialNum,condition,sketcherId,\\\n",
    "                                              iterationName)\n",
    "    \n",
    "## add URL column to dataframe\n",
    "M2 = M2.assign(url = M2.apply(lambda row: build_url(row,bucket_name=bucket_name,\\\n",
    "              gameID=row['gameID'],className=row['className'],repetition=row['repetition'],\\\n",
    "              trialNum=row['trialNum'],condition=row['condition'],sketcherId='both',\\\n",
    "              iterationName=row['iterationName']), axis=1))     \n",
    "    \n",
    "## add filename column\n",
    "M2 = M2.assign(filename = M2['url'].apply(lambda x: x.split('/')[-1]))\n",
    "\n",
    "## add empty games column (for sorting in database when sampling sketches to recognize)\n",
    "M2 = M2.assign(games = [[] for _ in range(len(M2))])\n",
    "\n",
    "## subset by whether this image is in the rendered png list that is on S3\n",
    "exists_in_metadata = M2['filename'].isin(png_list)\n",
    "M3 = M2[exists_in_metadata]\n",
    "\n",
    "## add \"shuffle_ind\" which determines order in which sketches are pulled out of database\n",
    "M3 = M3.assign(shuffler_ind = np.random.RandomState(0).permutation(np.arange(M3.shape[0]))) \n",
    "\n",
    "print 'Originally {} images in metadata. {} render-able images on S3.'.format(M2.shape[0],M3.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stimdict JSON to file.\n"
     ]
    }
   ],
   "source": [
    "## save json dictionary to file\n",
    "json_filename = 'collabdraw-collab8-recog-stimdict.js'\n",
    "json_filepath = os.path.join(results_dir,'json',json_filename)\n",
    "out = M3.to_json(json_filepath,orient='records')\n",
    "print 'Saved stimdict JSON to file.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload stimulus dictionary to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load JSON back in\n",
    "J = json.loads(open(json_filepath,mode='ru').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth_cogtoolslab.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## mongo db server ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']\n",
    "coll = db['collabdraw_collab8_recog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "runThis = 1\n",
    "if runThis:    \n",
    "    for (i,j) in enumerate(J):\n",
    "        if i%1==0:\n",
    "            print ('%d of %d uploaded ...' % (i,len(J)))\n",
    "            clear_output(wait=True)\n",
    "        coll.insert_one(j)  \n",
    "        \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 2848 records in the stimuli database for this experiment.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'There are {} records in the stimuli database for this experiment.'.format(coll.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
